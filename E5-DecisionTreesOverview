Los arboles de decisión son una técnica de aprendizaje supervisado para realizar prácticas de clasificación y de regresión con los datos, los cuales se detallan por las condiciones o características que se entran a evaluar para finalmente saber cuál sería el resultado. Dependiendo de los posibles valores de la variable respuesta, hay dos grupos: arboles de regresión y árboles de clasificación  
En los arboles de regresión la variable de decisión puede tomar valores continuos, mientras que en el árbol de clasificación la variable tiene un conjunto finito de valores que serían categorías.  
Ahora dependiendo del proceso para determinar el punto de referencia de división y la técnica de avance entre ramas, en conjunto con el tipo de variable a predecir, los arboles se distinguen en: 
Algoritmo ID3--> selecciona el atributo que subdivide de la mejor manera apoyándose los conceptos de entropía y ganancia para determinar las variables que aportan información relevante, eligiendo en cada momento el mejor atributo respecto a la respuesta que debe ser de tipo discreta. Lo malo es que tiende a favorecer a las categorías con participación mayoritaria. 
Algoritmo C4.5 --> es una versión mejorada de ID3 donde se manejan atributos discretos y continuos, para estos últimos se toma un valor punto de referencia clasificando así los que están por encima y los que se encuentran por debajo; permite valores nulos y no le asigna valores de ganancia y entropía. 
Algoritmo CART--> denominado también algoritmo de regresión y clasificación de tipo netamente binario tiene como criterio la combinación de los atributos como reglas para realizar la separación lo mejor posible dada por una función donde aquella que la máximize representa tener en cuenta esa regla y atributo como nodo para realizar la división. Adecuado para predición. 
Algoritmo CHAID--> está orientado al descubrimiento de interacciones entre las variables explicativas y la variable predictiva, óptimo para buscar patrones ó perfiles en conjuntos de datos con muchas variables categóricas. Es una técnica conveniente de resumir los datos, ya que las relaciones se pueden visualizar fácilmente. Emplea la prueba Chi cuadrado que mide la asociación entre dos variables. Especial para la segmentación de mercados y análisis.
